{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv('Data\\Consumer_Complaints_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=pd.read_csv('Data\\Consumer_Complaints_test_share.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Consumer disputed?']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['data'] = 'train'\n",
    "data_test['data'] = 'test'\n",
    "data_test=data_test[data_train.columns] # the columns in the two data frames should be in the same order to enable concatenation\n",
    "data_all=pd.concat([data_train,data_test],axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Garbage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "garbage_cols=data_all.isnull().sum()[data_all.isnull().sum()>(0.5*data_all.shape[0])].keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_all.drop(columns=garbage_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.drop(columns=[\"Complaint ID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"Sub-product\"]=np.where(data_all[\"Sub-product\"].isnull(),\"not_available\",data_all[\"Sub-product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"State\"]=np.where(data_all[\"State\"].isnull(),\"not_available\",data_all[\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"ZIP code\"]=np.where(data_all[\"ZIP code\"].isnull(),\"not_available\",data_all[\"ZIP code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"Submitted via\"]=np.where(data_all[\"Submitted via\"].isnull(),data_all[\"Submitted via\"].mode()[0],data_all[\"Submitted via\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=pd.to_datetime(data_all[\"Date received\"])\n",
    "d2=pd.to_datetime(data_all[\"Date sent to company\"])\n",
    "data_all[\"resolution_gap_days\"]=(d2-d1)/np.timedelta64(1,'D')\n",
    "data_all.drop(columns =[\"Date received\",\"Date sent to company\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(data,var,freq_cutoff=0):\n",
    "    t=data[var].value_counts(normalize=True)  #get value counts of all the unique data in specified feature variable \n",
    "    t=t[t.values>freq_cutoff] #filter the values having count less than specified cutoff\n",
    "    t=t.sort_values() #sort according to the value counts\n",
    "    t_min=t.idxmin() # get the data having minimum count \n",
    "    t=t.drop([t_min]) # drop that data as we make n-1 dummies \n",
    "    categories=t.index # making dummies for rest unique data values\n",
    "\n",
    "    for cat in categories :\n",
    "        name=var+'_'+cat\n",
    "        name=re.sub(\" \",\"\",name) \n",
    "        name=re.sub(\"-\",\"_\",name)\n",
    "        name=re.sub(\"\\\\?\",\"Q\",name) \n",
    "        name=re.sub(\"<\",\"LT_\",name) \n",
    "        name=re.sub(\"\\\\+\",\"\",name) \n",
    "        name=re.sub(\"\\\\/\",\"_\",name) \n",
    "        name=re.sub(\">\",\"GT_\",name) \n",
    "        name=re.sub(\"=\",\"EQ_\",name)\n",
    "        name=re.sub(\",\",\"\",name)\n",
    "        data[name]=(data[var]==cat)+0 \n",
    "               \n",
    "    data=data.drop(columns=[var]) #dropping original feature variable after making its dummies\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=dummies(data_all,\"Product\",0.03)\n",
    "data_all=dummies(data_all,\"Sub-product\",0.05)\n",
    "data_all=dummies(data_all,\"Issue\",0.02)\n",
    "data_all=dummies(data_all,\"Company\",0.02)\n",
    "data_all=dummies(data_all,\"State\",0.04)\n",
    "data_all=dummies(data_all,\"ZIP code\",0.002)\n",
    "data_all=dummies(data_all,\"Submitted via\",0.05)\n",
    "data_all=dummies(data_all,\"Company response to consumer\",0.05)\n",
    "data_all=dummies(data_all,\"Timely response?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_all[data_all['data']=='train'] \n",
    "del data_train['data'] \n",
    "data_test=data_all[data_all['data']=='test']\n",
    "data_test.drop(['Consumer disputed?','data'],axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, train2 = train_test_split(data_train, test_size = 0.2,random_state=2)\n",
    "\n",
    "x_train1=train1.drop([\"Consumer disputed?\"],1)\n",
    "y_train1=train1[\"Consumer disputed?\"]\n",
    "\n",
    "x_train2=train2.drop([\"Consumer disputed?\"],1)\n",
    "y_train2=train2[\"Consumer disputed?\"]\n",
    "\n",
    "x_train1.reset_index(drop=True,inplace=True)\n",
    "y_train1.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1params={'n_estimators':[100,200,500,700],\n",
    "       'criterion':['gini','entropy'],\n",
    "       'min_samples_split':[5,7,9],\n",
    "       'bootstrap':[True],\n",
    "        'n_jobs':[-1],\n",
    "       'max_depth':[5,10,20],\n",
    "       'max_features':[5,10,20,30,40], \n",
    "       'min_samples_leaf':[6,8,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*2*5*2*5*7*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(clf, param_distributions=x_train1params,\n",
    "                                   n_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight='balanced',\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=...\n",
       "                   iid='warn', n_iter=150, n_jobs=None,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 20],\n",
       "                                        'max_features': [5, 10, 20, 30, 40],\n",
       "                                        'min_samples_leaf': [6, 8, 10],\n",
       "                                        'min_samples_split': [5, 7, 9],\n",
       "                                        'n_estimators': [100, 200, 500, 700],\n",
       "                                        'n_jobs': [-1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=5, max_features=40,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=10,\n",
       "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=700, n_jobs=-1, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=random_search.best_estimator_\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=5, max_features=40,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=10,\n",
       "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=700, n_jobs=-1, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57690196, 0.40671795, 0.52087031, ..., 0.48828955, 0.38531605,\n",
       "       0.48716749])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_score=rf.predict_proba(x_train1)[:,1]\n",
    "train1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33398213, 0.39484201, 0.57146849, ..., 0.58341717, 0.4964964 ,\n",
       "       0.57703189])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_score=rf.predict_proba(x_train2)[:,1]\n",
    "train2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.54145938714937"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_classes=(train1_score>0.5).astype(int)\n",
    "y_train1_classes=np.where(y_train1==\"Yes\",1,0)\n",
    "train1_score[train1_score>0.5].size*100/train1_score.size #percent of Yes in train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.28045148142342"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_classes=(train2_score>0.5).astype(int)\n",
    "y_train2_classes=np.where(y_train2==\"Yes\",1,0)\n",
    "train2_score[train2_score>0.5].size*100/train2_score.size #percent of Yes in train 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5777269278863529"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train1, train1_classes) #auc score of train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.578932276110413"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train2, train2_classes) #auc score of train 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score=rf.predict_proba(data_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score\n",
    "test_classes=np.where(test_score>0.5,\"Yes\",\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60521"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes[test_classes==\"No\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     301424\n",
       "Yes     81312\n",
       "Name: Consumer disputed?, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['Consumer disputed?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_classes).to_csv(\"laveena_valecha_project_RF.csv\",header=\"Consumer disputed?\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
